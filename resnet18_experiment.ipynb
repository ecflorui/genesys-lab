{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPf9v7QoPZ0QZJZdJ5KnFw+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecflorui/genesys-lab/blob/main/resnet18_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwIgzOG50sTt",
        "outputId": "7a5d26a6-1bd3-4b29-f391-779521877477"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6X-H-oO0qvA",
        "outputId": "3d097fb1-a939-44cf-b7d6-d7fd0f372b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking files in: /content/drive/MyDrive/v5\n",
            "Missing .npy for: /content/drive/MyDrive/v5/20250721_164649.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v5/20250721_181726.jpg\n",
            "Checking files in: /content/drive/MyDrive/v6 (1)\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_163126.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_171303.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_174704.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_183244.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_185623.jpg\n",
            "Missing .npy for: /content/drive/MyDrive/v6 (1)/20250722_190931.jpg\n",
            "Total valid samples found: 587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s]\n",
            "Epoch 1: 100%|██████████| 15/15 [03:44<00:00, 15.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss=1.0246, Acc=0.6162 | Val Loss=1.1968, Acc=0.5932\n",
            "Saved new best model with Val Acc: 0.5932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 15/15 [01:19<00:00,  5.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss=0.6644, Acc=0.7591 | Val Loss=1.1246, Acc=0.6186\n",
            "Saved new best model with Val Acc: 0.6186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 15/15 [01:20<00:00,  5.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss=0.3109, Acc=0.9360 | Val Loss=1.1530, Acc=0.6525\n",
            "Saved new best model with Val Acc: 0.6525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 15/15 [01:19<00:00,  5.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss=0.1257, Acc=0.9979 | Val Loss=1.2702, Acc=0.6017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 15/15 [01:18<00:00,  5.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss=0.0512, Acc=1.0000 | Val Loss=1.4214, Acc=0.5763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 15/15 [01:19<00:00,  5.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss=0.0284, Acc=0.9979 | Val Loss=1.5281, Acc=0.5254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 15/15 [01:20<00:00,  5.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss=0.0240, Acc=0.9979 | Val Loss=1.6580, Acc=0.5593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8:  80%|████████  | 12/15 [01:04<00:16,  5.41s/it]"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# -------- Paths (Google Drive) --------\n",
        "v5_path = '/content/drive/MyDrive/v5'\n",
        "v6_path = '/content/drive/MyDrive/v6 (1)'\n",
        "save_path = '/content/drive/MyDrive/best_model_resnet18.pth'\n",
        "\n",
        "# -------- Hyperparameters --------\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "PATIENCE = 5\n",
        "\n",
        "# -------- Dataset Class --------\n",
        "class ImageLabelDataset(Dataset):\n",
        "    def __init__(self, root_dirs, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        for root in root_dirs:\n",
        "            print(f\"Checking files in: {root}\")\n",
        "            for image_file in glob.glob(os.path.join(root, '*.*')):\n",
        "                if image_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    npy_file = os.path.splitext(image_file)[0] + '.npy'\n",
        "                    if os.path.exists(npy_file):\n",
        "                        self.samples.append((image_file, npy_file))\n",
        "                    else:\n",
        "                        print(f\"Missing .npy for: {image_file}\")\n",
        "        print(f\"Total valid samples found: {len(self.samples)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label_path = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label_vec = np.load(label_path)\n",
        "        label = int(np.argmax(label_vec))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# -------- Transforms --------\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# -------- Load Data --------\n",
        "full_dataset = ImageLabelDataset([v5_path, v6_path])\n",
        "\n",
        "if len(full_dataset) == 0:\n",
        "    raise ValueError(\"Dataset is empty. Check your Drive paths and file formats.\")\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_ds.dataset.transform = train_transform\n",
        "val_ds.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "# -------- Model --------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "base_model = models.resnet18(pretrained=True)\n",
        "num_features = base_model.fc.in_features\n",
        "base_model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(num_features, 4)\n",
        ")\n",
        "model = base_model.to(device)\n",
        "\n",
        "# -------- Loss and Optimizer --------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# -------- Evaluation Function --------\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    correct, total, loss_sum = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum += loss.item() * imgs.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return loss_sum / total, correct / total\n",
        "\n",
        "# -------- Training Loop --------\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for imgs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_loss, train_acc = evaluate(train_loader)\n",
        "    val_loss, val_acc = evaluate(val_loader)\n",
        "    print(f'Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | Val Loss={val_loss:.4f}, Acc={val_acc:.4f}')\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Saved new best model with Val Acc: {val_acc:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n"
      ]
    }
  ]
}